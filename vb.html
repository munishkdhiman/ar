<script type="text/javascript">
        var gk_isXlsx = false;
        var gk_xlsxFileLookup = {};
        var gk_fileData = {};
        function filledCell(cell) {
          return cell !== '' && cell != null;
        }
        function loadFileData(filename) {
        if (gk_isXlsx && gk_xlsxFileLookup[filename]) {
            try {
                var workbook = XLSX.read(gk_fileData[filename], { type: 'base64' });
                var firstSheetName = workbook.SheetNames[0];
                var worksheet = workbook.Sheets[firstSheetName];

                // Convert sheet to JSON to filter blank rows
                var jsonData = XLSX.utils.sheet_to_json(worksheet, { header: 1, blankrows: false, defval: '' });
                // Filter out blank rows (rows where all cells are empty, null, or undefined)
                var filteredData = jsonData.filter(row => row.some(filledCell));

                // Heuristic to find the header row by ignoring rows with fewer filled cells than the next row
                var headerRowIndex = filteredData.findIndex((row, index) =>
                  row.filter(filledCell).length >= filteredData[index + 1]?.filter(filledCell).length
                );
                // Fallback
                if (headerRowIndex === -1 || headerRowIndex > 25) {
                  headerRowIndex = 0;
                }

                // Convert filtered JSON back to CSV
                var csv = XLSX.utils.aoa_to_sheet(filteredData.slice(headerRowIndex)); // Create a new sheet from filtered array of arrays
                csv = XLSX.utils.sheet_to_csv(csv, { header: 1 });
                return csv;
            } catch (e) {
                console.error(e);
                return "";
            }
        }
        return gk_fileData[filename] || "";
        }
        </script><!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D Avatar Chatbot with RAG</title>
    <style>
        body {
            margin: 0;
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
            display: flex;
            flex-direction: column;
            align-items: center;
            height: 100vh;
            overflow: hidden;
        }
        #canvas-container {
            width: 100%;
            max-width: 600px;
            height: 300px;
            border: 2px solid #333;
            background-color: #000;
        }
        #chat-container {
            width: 100%;
            max-width: 600px;
            height: 200px;
            overflow-y: auto;
            border: 1px solid #ccc;
            padding: 10px;
            background-color: #fff;
            margin-top: 10px;
        }
        #input-container {
            width: 100%;
            max-width: 600px;
            display: flex;
            margin-top: 10px;
        }
        #pdf-upload-container {
            width: 100%;
            max-width: 600px;
            margin-top: 10px;
        }
        #user-input {
            flex: 1;
            padding: 10px;
            font-size: 16px;
        }
        #voice-btn {
            padding: 10px;
            font-size: 16px;
            cursor: pointer;
            background-color: #28a745;
            color: white;
            border: none;
        }
        #voice-btn:hover {
            background-color: #218838;
        }
        #voice-btn:disabled {
            background-color: #ccc;
            cursor: not-allowed;
        }
        #pdf-upload {
            padding: 10px;
        }
    </style>
</head>
<body>
    <div id="canvas-container"></div>
    <div id="pdf-upload-container">
        <label for="pdf-upload">Upload a PDF document to start:</label>
        <input type="file" id="pdf-upload" accept=".pdf">
    </div>
    <div id="chat-container"></div>
    <div id="input-container">
        <input type="text" id="user-input" placeholder="Type your question or use voice..." disabled>
        <button id="voice-btn" disabled>ðŸŽ¤ Speak</button>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.10.377/pdf.min.js"></script>
    <script src="https://code.responsivevoice.org/responsivevoice.js?key=swgTaRZL"></script>
    <script>
        // Replace with your Open AI API key
        const OPENAI_API_KEY = 'sk-proj-kS4lqQqrTds8jYjjAqafT3BlbkFJrgqvQaJsR4wodUCWgiMI';

        // Three.js setup
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, 600 / 300, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer();
        renderer.setSize(600, 300);
        document.getElementById('canvas-container').appendChild(renderer.domElement);

        // Create a simple 3D avatar (a sphere as a head)
        const geometry = new THREE.SphereGeometry(1, 32, 32);
        const material = new THREE.MeshBasicMaterial({ color: 0xffa500 });
        const avatar = new THREE.Mesh(geometry, material);
        scene.add(avatar);

        // Lighting
        const light = new THREE.AmbientLight(0xffffff);
        scene.add(light);

        // Camera position
        camera.position.z = 3;

        // Animation loop
        function animate() {
            requestAnimationFrame(animate);
            avatar.rotation.y += 0.01;
            renderer.render(scene, camera);
        }
        animate();

        // Chat elements
        const chatContainer = document.getElementById('chat-container');
        const userInput = document.getElementById('user-input');
        const voiceBtn = document.getElementById('voice-btn');
        const pdfUpload = document.getElementById('pdf-upload');

        // PDF context storage
        let pdfContext = '';

        // PDF upload and text extraction
        pdfUpload.addEventListener('change', async (event) => {
            const file = event.target.files[0];
            if (!file || !file.type.includes('pdf')) {
                displayMessage('System: Please upload a valid PDF file.');
                return;
            }

            displayMessage('System: Processing PDF...');
            try {
                const arrayBuffer = await file.arrayBuffer();
                const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise;
                let text = '';

                for (let i = 1; i <= pdf.numPages; i++) {
                    const page = await pdf.getPage(i);
                    const content = await page.getTextContent();
                    text += content.items.map(item => item.str).join(' ') + ' ';
                }

                // Truncate text to avoid Open AI token limits (approx. 3000 tokens ~ 12,000 chars)
                pdfContext = text.substring(0, 12000);
                displayMessage('System: PDF processed successfully. You can now ask questions based on the document.');
                userInput.disabled = false;
                if (SpeechRecognition) voiceBtn.disabled = false;
            } catch (error) {
                console.error('PDF processing error:', error);
                displayMessage('System: Error processing PDF. Please try another file.');
            }
        });

        // Check for Web Speech API support
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition = null;
        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'en-US';
            recognition.interimResults = false;
        } else {
            displayMessage('System: Speech recognition is not supported in this browser. Please use text input.');
        }

        let isListening = false;

        if (recognition) {
            voiceBtn.addEventListener('click', () => {
                if (!pdfContext) {
                    displayMessage('System: Please upload a PDF first.');
                    return;
                }
                if (!isListening) {
                    try {
                        recognition.start();
                        voiceBtn.textContent = 'ðŸ”´ Stop';
                        isListening = true;
                    } catch (e) {
                        displayMessage('System: Failed to start speech recognition. Please ensure microphone access.');
                    }
                } else {
                    recognition.stop();
                    voiceBtn.textContent = 'ðŸŽ¤ Speak';
                    isListening = false;
                }
            });

            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                userInput.value = transcript;
                sendMessage(transcript);
            };

            recognition.onerror = (event) => {
                let errorMessage = 'System: Speech recognition error - ';
                switch (event.error) {
                    case 'not-allowed':
                        errorMessage += 'Microphone access denied. Please allow microphone access in your browser settings.';
                        break;
                    case 'no-speech':
                        errorMessage += 'No speech detected. Please try speaking clearly.';
                        break;
                    case 'audio-capture':
                        errorMessage += 'No microphone detected. Please ensure your microphone is connected.';
                        break;
                    case 'network':
                        errorMessage += 'Network error. Please check your internet connection.';
                        break;
                    case 'aborted':
                        errorMessage += 'Speech recognition was aborted.';
                        break;
                    default:
                        errorMessage += `Unknown error (${event.error}).`;
                }
                displayMessage(errorMessage);
                voiceBtn.textContent = 'ðŸŽ¤ Speak';
                isListening = false;
            };

            recognition.onend = () => {
                voiceBtn.textContent = 'ðŸŽ¤ Speak';
                isListening = false;
            };
        }

        // Send message on Enter key
        userInput.addEventListener('keypress', (e) => {
            if (e.key === 'Enter' && userInput.value.trim()) {
                if (!pdfContext) {
                    displayMessage('System: Please upload a PDF first.');
                    return;
                }
                sendMessage(userInput.value);
            }
        });

        // Function to display messages in chat container
        function displayMessage(message) {
            const messageElement = document.createElement('p');
            messageElement.textContent = message;
            chatContainer.appendChild(messageElement);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        // Function to send message to Open AI with RAG
        async function sendMessage(message) {
            // Display user message
            displayMessage(`You: ${message}`);
            userInput.value = '';

            try {
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${OPENAI_API_KEY}`
                    },
                    body: JSON.stringify({
                        model: 'gpt-3.5-turbo',
                        messages: [
                            {
                                role: 'system',
                                content: 'You are a helpful assistant. Use the following document context to answer questions accurately. If the question is unrelated to the document, use your general knowledge but clarify that the answer is not based on the document.\n\nDocument Context:\n' + pdfContext
                            },
                            { role: 'user', content: message }
                        ],
                        max_tokens: 150
                    })
                });

                if (!response.ok) {
                    throw new Error(`HTTP error ${response.status}`);
                }

                const data = await response.json();
                const botReply = data.choices[0].message.content.trim();

                // Display bot message
                displayMessage(`Bot: ${botReply}`);

                // Speak the response using TTS
                if (responsiveVoice) {
                    responsiveVoice.speak(botReply, 'UK English Male', { rate: 1.0 });
                } else {
                    displayMessage('System: Text-to-speech is unavailable.');
                }
            } catch (error) {
                console.error('Error with Open AI API:', error);
                displayMessage('Bot: Sorry, something went wrong with the AI service.');
            }
        }
    </script>
</body>
</html>